{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43885103-5f0f-4799-8243-1ad7eb80d0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.1 (from langchain-community)\n",
      "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-community) (3.13.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.0)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.1->langchain-community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.10.5)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.4.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.4.38-py3-none-any.whl (397 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
      "Downloading orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: typing-inspect, python-dotenv, pypdf, orjson, marshmallow, jsonpatch, httpx-sse, httpcore, async-timeout, requests-toolbelt, dataclasses-json, pydantic-settings, httpx, langsmith, langchain-core, langchain-text-splitters, langchain-classic, langchain-community\n",
      "\u001b[2K  Attempting uninstall: marshmallow━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [pypdf]\n",
      "\u001b[2K    Found existing installation: marshmallow 4.0.1━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [pypdf]\n",
      "\u001b[2K    Uninstalling marshmallow-4.0.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [pypdf]\n",
      "\u001b[2K      Successfully uninstalled marshmallow-4.0.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [pypdf]\n",
      "\u001b[2K  Attempting uninstall: async-timeout\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/18\u001b[0m [httpcore]ow]\n",
      "\u001b[2K    Found existing installation: async-timeout 5.0.1━━━━━━━━━━\u001b[0m \u001b[32m 7/18\u001b[0m [httpcore]\n",
      "\u001b[2K    Uninstalling async-timeout-5.0.1:m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/18\u001b[0m [httpcore]\n",
      "\u001b[2K      Successfully uninstalled async-timeout-5.0.1━━━━━━━━━━━━\u001b[0m \u001b[32m 7/18\u001b[0m [httpcore]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed async-timeout-4.0.3 dataclasses-json-0.6.7 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 jsonpatch-1.33 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.1 langchain-text-splitters-1.0.0 langsmith-0.4.38 marshmallow-3.26.1 orjson-3.11.4 pydantic-settings-2.11.0 pypdf-6.1.3 python-dotenv-1.2.1 requests-toolbelt-1.0.0 typing-inspect-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\n",
      "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.19 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting langchain\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.0.1)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (2.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.38)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
      "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading ormsgpack-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [langchain]/7\u001b[0m [langchain]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-1.0.2 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 ormsgpack-1.11.0 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community pypdf\n",
    "!pip install -qU langchain-aws\n",
    "!pip install -qU langchain-chroma\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f08758-4b4f-4916-9eba-91e6ce8855b2",
   "metadata": {},
   "source": [
    "## Add the required import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f629906d-112b-4025-aa1f-62a92465aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "from langchain.tools import tool\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c72ca5-bfb5-4702-bf73-0569672b5ef2",
   "metadata": {},
   "source": [
    "## Method to read the pdf content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b075b401-0c18-4c98-8a56-3142a575dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ccb0e0d-1ab9-420c-9863-e4c9ae598a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "pdf_content = load_pdf(file_path='SystemDesignInterview_1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0aa679-415c-43b0-ac31-b4fe3ba8d511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(pdf_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a995f74-c13e-44de-b7c2-bcc2ce5b81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_by_splitter(file_path):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "       chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    "    )\n",
    "    doc = load_pdf(file_path)\n",
    "    all_splits = text_splitter.split_documents(doc)\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064500e9-6052-4a37-8d65-d554d5d074da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "pdf_content_by_splitter = load_pdf_by_splitter(file_path='SystemDesignInterview_1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64a921d-f6d0-4261-8ff3-aa6bb942ac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vertical scaling vs horizontal scaling Vertical scaling, referred to as “scale up” , means the process of adding more power (CPU, RAM, etc.) to your servers. Horizontal scaling, referred to as “scale-out” , allows you to scale by adding more servers into your pool of resources. When traffic is low, vertical scaling is a great option, and the simplicity of vertical scaling is its main advantage. Unfortunately, it comes with serious limitations. • Vertical scaling has a hard limit. It is impossible to add unlimited CPU and memory to a single server. • Vertical scaling does not have failover and redundancy. If one server goes down, the website/app goes down with it completely. Horizontal scaling is more desirable for large scale applications due to the limitations of vertical scaling. In the previous design, users are connected to the web server directly. Users will unable to access the website if the web server is offline. In another scenario, if many users access the web server'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_content_by_splitter[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ba22e-a572-4ca1-911b-43388d943ca4",
   "metadata": {},
   "source": [
    "## Generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cd0fba-46fb-4d64-ad13-2e954fd2d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cfce047-ffec-4814-82b4-4949e5262668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding():\n",
    "    embeddings = []\n",
    "    for content in pdf_content_by_splitter:\n",
    "        current_embedding = embedding_model.embed_query(content.page_content)\n",
    "        embeddings.append(current_embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "249378a0-f3eb-4f3a-8c08-781a5ddcea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using AI snadbox to test my learning and due to contraints i should not create more token\n",
    "#len(generate_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4bc234",
   "metadata": {},
   "source": [
    "## Store embedding into Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f97bb68-f5c0-4fc7-bac9-219d13cc7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embedding():\n",
    "    persist_dir = \"./chroma_system_design_db_4\"\n",
    "    collection_name = \"system_design_collection\"\n",
    "\n",
    "    # If persisted data exists, instantiate and reuse without adding documents.\n",
    "    if os.path.exists(persist_dir) and any(os.scandir(persist_dir)):\n",
    "        vector_store = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embedding_model,\n",
    "            persist_directory=persist_dir,\n",
    "        )\n",
    "        print(f\"Reusing existing vector store at {persist_dir}\")\n",
    "        return vector_store\n",
    "\n",
    "    # Otherwise create, add documents and persist.\n",
    "    vector_store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embedding_model,\n",
    "        persist_directory=persist_dir,\n",
    "    )\n",
    "\n",
    "    vector_store.add_documents(pdf_content_by_splitter)\n",
    "    try:\n",
    "        vector_store.persist()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"Created and persisted new vector store at {persist_dir}\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb625ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and persisted new vector store at ./chroma_system_design_db_4\n"
     ]
    }
   ],
   "source": [
    "vector_store = store_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c0543",
   "metadata": {},
   "source": [
    "## Getting the related documents for the provided query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6078599",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def search_query_by_similarty_search(query: str, k: int = 1) -> List[Document]:\n",
    "    return vector_store.similarity_search(query, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab4df7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical scaling vs horizontal scaling Vertical scaling, referred to as “scale up” , means the process of adding more power (CPU, RAM, etc.) to your servers. Horizontal scaling, referred to as “scale-out” , allows you to scale by adding more servers into your pool of resources. When traffic is low, vertical scaling is a great option, and the simplicity of vertical scaling is its main advantage. Unfortunately, it comes with serious limitations. • Vertical scaling has a hard limit. It is impossible to add unlimited CPU and memory to a single server. • Vertical scaling does not have failover and redundancy. If one server goes down, the website/app goes down with it completely. Horizontal scaling is more desirable for large scale applications due to the limitations of vertical scaling. In the previous design, users are connected to the web server directly. Users will unable to access the website if the web server is offline. In another scenario, if many users access the web server\n"
     ]
    }
   ],
   "source": [
    "retriever_results = search_query_by_similarty_search.batch(['what is horizontal scaling'])\n",
    "for result in retriever_results:\n",
    "    print(result[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4e044",
   "metadata": {},
   "source": [
    "## RAG agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e1aad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = init_chat_model(\n",
    "    \"openai.gpt-oss-120b-1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f8bf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_similar_documents(query: str, k: int) -> List[str]:\n",
    "    \"\"\"Return page_content strings for the top-k similar documents.\n",
    "\n",
    "    Args:\n",
    "        query: Query string to search.\n",
    "        k: Number of documents to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: page_content of retrieved documents.\n",
    "    \"\"\"\n",
    "    retrieved_documents = []\n",
    "    results = search_query_by_similarty_search.batch([(query, k)])\n",
    "    for search_similar_document in results:\n",
    "        retrieved_documents.extend(search_similar_document.page_content)\n",
    "    return retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b54fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_pipeline(query: str):\n",
    "    tools = [search_similar_documents]\n",
    "    prompt = \"Only answer using the supplied conversation and documents. Do not use or invent information from your pretraining. If the content does not contain the answer, respond I don't know.\"\n",
    "    agent = create_agent(chat_model, tools, system_prompt=prompt)\n",
    "    for event in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "263167dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************What is Nitya\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Nitya\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'reasoning_content', 'reasoning_content': {'text': 'The user asks: \"What is Nitya\". Likely they want definition. Could be a name, Indian term meaning \"eternal\", also a brand or company. Need to answer succinctly. Provide meaning. Let\\'s answer: Nitya is a Sanskrit word meaning \"eternal\", \"permanent\", also used as a name, also a company named Nitya. Provide context.', 'signature': ''}}, {'type': 'text', 'text': '**Nitya** (नीत्य) is a Sanskrit word that means “eternal,” “permanent,” or “ever‑lasting.” It is commonly used in Indian philosophical and spiritual texts to describe the timeless nature of reality, the soul, or divine principles.\\n\\nBecause of its positive connotation, **Nitya** is also used as a personal name for both boys and girls in India and among the Indian diaspora.  \\n\\nIn addition, “Nitya” appears as a brand name for various companies and products (e.g., Nitya\\u202fTech, Nitya\\u202fFinance, Nitya\\u202fWellness), typically chosen to convey reliability and lasting value.'}]\n"
     ]
    }
   ],
   "source": [
    "build_rag_pipeline(\"What is Nitya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d9e9e-c19e-4495-a8d3-b46ecf6fa7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
